{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dynamic FAISS Sentence RAG Demo\n",
        "\n",
        "- FAISS index for vector similarity search\n",
        "- Runtime insertion of new sentences\n",
        "- Paragraph query returns top-N most relevant memory sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34273808",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q faiss-cpu sentence-transformers numpy ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8918954a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jakemckenna/Code/dungeon-masters-companion/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e16d51ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "SENTENCE_SPLIT_RE = re.compile(r\"(?<=[.!?])\\s+|\\n+\")\n",
        "\n",
        "def split_into_sentences(text: str) -> List[str]:\n",
        "    parts = [p.strip() for p in SENTENCE_SPLIT_RE.split(text or \"\") if p.strip()]\n",
        "    return parts\n",
        "\n",
        "@dataclass\n",
        "class SearchHit:\n",
        "    sentence: str\n",
        "    score: float\n",
        "\n",
        "class DynamicSentenceMemory:\n",
        "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.index = None\n",
        "        self.sentences: List[str] = []\n",
        "\n",
        "    def _embed(self, texts: List[str]) -> np.ndarray:\n",
        "        vectors = self.model.encode(\n",
        "            texts,\n",
        "            convert_to_numpy=True,\n",
        "            normalize_embeddings=True,\n",
        "        ).astype(np.float32)\n",
        "        return vectors\n",
        "\n",
        "    def add_sentences(self, sentences: List[str]) -> None:\n",
        "        clean = [s.strip() for s in sentences if s and s.strip()]\n",
        "        if not clean:\n",
        "            return\n",
        "\n",
        "        vectors = self._embed(clean)\n",
        "        if self.index is None:\n",
        "            self.index = faiss.IndexFlatIP(vectors.shape[1])\n",
        "        self.index.add(vectors)\n",
        "        self.sentences.extend(clean)\n",
        "\n",
        "    def add_text(self, text: str) -> None:\n",
        "        self.add_sentences(split_into_sentences(text))\n",
        "\n",
        "    def search(self, paragraph: str, top_n: int = 3) -> List[SearchHit]:\n",
        "        if self.index is None or not self.sentences:\n",
        "            return []\n",
        "\n",
        "        query = self._embed([paragraph])\n",
        "        k = min(top_n, len(self.sentences))\n",
        "        scores, idxs = self.index.search(query, k)\n",
        "\n",
        "        hits: List[SearchHit] = []\n",
        "        for score, idx in zip(scores[0], idxs[0]):\n",
        "            if idx < 0:\n",
        "                continue\n",
        "            hits.append(SearchHit(sentence=self.sentences[int(idx)], score=float(score)))\n",
        "        return hits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a57fd95d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Mitch keeps spare boots under his bed.\n",
            "- Mictch hides his knives in the cellar of the copper cup.\n",
            "- Mitch is secretly murdering people in the town.\n",
            "- Mitch and the Wizard hate eachother.\n",
            "- Mitch knows the Wizard is reviving his victims.\n",
            "- Mitch wants to manipulate the player into killing the Wizard for him.\n",
            "- Mitch secretly kills people at night.\n",
            "- Mitch suspects the player stole his boots.\n",
            "- Mitch is barefoot and very angry about it.\n",
            "Indexed sentences: 9\n"
          ]
        }
      ],
      "source": [
        "memory = DynamicSentenceMemory()\n",
        "\n",
        "seed_text = \"\"\"\n",
        "Mitch keeps spare boots under his bed.\n",
        "Mictch hides his knives in the cellar of the copper cup.\n",
        "Mitch is secretly murdering people in the town.\n",
        "Mitch and the Wizard hate eachother.\n",
        "Mitch knows the Wizard is reviving his victims.\n",
        "Mitch wants to manipulate the player into killing the Wizard for him.\n",
        "Mitch secretly kills people at night.\n",
        "\"\"\"\n",
        "\n",
        "memory.add_text(seed_text)\n",
        "\n",
        "# Runtime insertion: add new facts during play\n",
        "memory.add_sentences([\n",
        "    \"Mitch suspects the player stole his boots.\",\n",
        "    \"Mitch is barefoot and very angry about it.\",\n",
        "])\n",
        "\n",
        "\n",
        "for sentence in memory.sentences:\n",
        "    print(f\"- {sentence}\")\n",
        "print(f\"Indexed sentences: {len(memory.sentences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c13786c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. score=0.2383 | Mitch keeps spare boots under his bed.\n",
            "2. score=0.2120 | Mitch suspects the player stole his boots.\n",
            "3. score=0.1546 | Mitch is barefoot and very angry about it.\n",
            "4. score=0.1205 | Mictch hides his knives in the cellar of the copper cup.\n"
          ]
        }
      ],
      "source": [
        "query_paragraph_chat = \"\"\"\n",
        "I say to Mitch, whats going on with the shoes there buddy? You're walking around barefoot in the middle of the night; and why do you have blood on your hands.\n",
        "\"\"\"\n",
        "query_knives = \"\"\"\n",
        "Weapons\n",
        "\"\"\"\n",
        "query_boots = \"\"\"\n",
        "clothing\n",
        "\"\"\"\n",
        "query_murder = \"\"\"\n",
        "stab\n",
        "\"\"\"\n",
        "\n",
        "top_n = 4\n",
        "hits = memory.search(query_boots, top_n=top_n) #swap out the query to see how nuanced the matching can be here. -JM\n",
        "\n",
        "for rank, hit in enumerate(hits, start=1):\n",
        "    print(f\"{rank}. score={hit.score:.4f} | {hit.sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52fb3a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"Minimal entity model and memory retrieval tool.\"\"\"\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Entity:\n",
        "    name: str\n",
        "    description: str\n",
        "    memory: DynamicSentenceMemory\n",
        "\n",
        "\n",
        "ENTITY_REGISTRY: Dict[str, Entity] = {}\n",
        "\n",
        "# If we need to pass the entity registry to help the tool calls stay accurate then we need to make sure this spec is updated before each tool call. For now static is fine. -JM\n",
        "OLLAMA_TOOL_SPEC: Dict[str, Any] = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"retrieve_memory_tool\",\n",
        "        \"description\": \"Retrieve memory for a registered entity.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"entity_name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Name of the registered entity.\",\n",
        "                    #\"enum\": list(ENTITY_REGISTRY.keys()), #Uncomment this to add the entity keys as options, could help coherence -JM \n",
        "                },\n",
        "                \"context\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Context used for similarity search.\",\n",
        "                },\n",
        "                \"top_n\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"Maximum number of memories to return.\",\n",
        "                    \"minimum\": 1,\n",
        "                    \"default\": 4,\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"entity_name\", \"context\"],\n",
        "            \"additionalProperties\": False,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def register_entity(entity: Entity) -> None:\n",
        "    \"\"\"Register an entity so the tool can retrieve its memory.\"\"\"\n",
        "    ENTITY_REGISTRY[entity.name.lower().strip()] = entity\n",
        "\n",
        "\n",
        "def retrieve_memory_tool(entity_name: str, context: str, top_n: int = 4) -> Dict[str, Any]:\n",
        "    \"\"\"Return top-N memory hits for a registered entity.\"\"\"\n",
        "    entity = ENTITY_REGISTRY.get(entity_name.lower().strip())\n",
        "    if entity is None:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"message\": f\"Entity '{entity_name}' is not registered.\",\n",
        "            \"memories\": [],\n",
        "        }\n",
        "\n",
        "    hits = entity.memory.search(context, top_n=top_n)\n",
        "    return {\n",
        "        \"success\": True,\n",
        "        \"entity_name\": entity.name,\n",
        "        \"memories\": [\n",
        "            {\"sentence\": hit.sentence, \"score\": float(hit.score)}\n",
        "            for hit in hits\n",
        "        ],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ea53544c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved memory:\n",
            "- 0.7300: Mitch is barefoot and very angry about it.\n",
            "- 0.6022: Mitch keeps spare boots under his bed.\n",
            "- 0.5448: Mitch suspects the player stole his boots.\n",
            "- 0.5192: Mitch secretly kills people at night.\n",
            "\n",
            "LLM response:\n",
            "The chipped linoleum feels cold under your own feet as you speak, a stark contrast to the simmering heat radiating from Mitch. He stops pacing, his jaw tight, and fixes you with a glare that could curdle milk. “What’s going on with the shoes?” he echoes, the question laced with venom. He holds up his hands, examining the crimson staining his palms as if surprised to find it there. “What’s going on? *You* tell *me* what’s going on. You waltz in here in the dead of night, and *I’m* the one who has to explain why I’m comfortable in my own home? And don’t play innocent about the boots. They were right there, under the bed, and now they’re gone. You’re the only one who’s been in here.” He takes a step closer, his voice dropping to a dangerous whisper. “Don’t insult my intelligence.”\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "repo_root = Path.cwd()  # in the notebook directories get broken, this fixes it -JM\n",
        "if not (repo_root / \"orchestrator\").exists() and (repo_root.parent / \"orchestrator\").exists():\n",
        "    repo_root = repo_root.parent\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.append(str(repo_root))\n",
        "\n",
        "from orchestrator.llm_interaction.adapter import LLMAdapter\n",
        "from orchestrator.runtime_flow.step_registry import build_steps\n",
        "\n",
        "register_entity(\n",
        "    Entity(\n",
        "        name=\"Mitch\",\n",
        "        description=\"Suspicious townsman with hidden motives.\",\n",
        "        memory=memory,\n",
        "    )\n",
        ")\n",
        "\n",
        "query_text = query_paragraph_chat.strip()\n",
        "tool_result = retrieve_memory_tool(\"Mitch\", query_text, top_n=4)\n",
        "if not tool_result[\"success\"]:\n",
        "    raise ValueError(tool_result.get(\"message\", \"Memory retrieval failed.\"))\n",
        "\n",
        "memory_context = \"\\n\".join(\n",
        "    f\"- {item['sentence']} (score={item['score']:.4f})\"\n",
        "    for item in tool_result[\"memories\"]\n",
        ") or \"- None\"\n",
        "\n",
        "adapter = LLMAdapter(\n",
        "    model=\"gemma3:27b\",\n",
        "    default_options={\"temperature\": 0, \"top_p\": 0.9},\n",
        "    stage_options={\"narrate\": {\"temperature\": 0, \"top_p\": 0.93}},\n",
        ")\n",
        "\n",
        "steps = build_steps()\n",
        "payload_text = f\"\"\"\n",
        "# Retrieved Memory\n",
        "{memory_context}\n",
        "\n",
        "# Player Input\n",
        "{query_text}\n",
        "\"\"\".strip()\n",
        "\n",
        "narrative, _ = steps[\"narrate\"].run(adapter, payload_text)\n",
        "\n",
        "print(\"Retrieved memory:\")\n",
        "for item in tool_result[\"memories\"]:\n",
        "    print(f\"- {item['score']:.4f}: {item['sentence']}\")\n",
        "\n",
        "print(\"\\nLLM response:\")\n",
        "print(narrative)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
